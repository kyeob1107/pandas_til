{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object creation (2024-01-26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(\"20130101\", periods=6)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list(\"ABCD\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": 1.0,\n",
    "        \"B\": pd.Timestamp(\"20130102\"),\n",
    "        \"C\": pd.Series(1,index=list(range(4)),dtype=\"float32\"),\n",
    "        \"D\": np.array([3]*4, dtype=\"int32\"),\n",
    "        \"E\": pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "        \"F\": \"foo\", #특이한게 ,로 끝내도 되고 아닌 것으로 끝내도 되네?\n",
    "    }\n",
    ")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.<TAB> # noqa: E225, E999\n",
    "\n",
    "#df2.까지 입력후 탭누르라는 의미, vscode에서는 탭안눌러도 자동으로 표시 단 컬럼은 안 표시됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing data (2024-01-27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T\n",
    "#행과 열을 바꿔주는데 미리 계산되어 있음\n",
    "#메소드가 아닌 속성임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.index\n",
    "#값만 바꿔서 나타내는가해서 확인용으로 해줬는데 인덱스도 확실히 바뀌어있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(axis=1, ascending=False)\n",
    "#axis = 1 하면 열끼리 정렬하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"B\")\n",
    "#df안에 있는 특정 열의 값에 대해서 정렬해줄 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection (2024-01-28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getitem ([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"20130102\":\"20130104\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[dates[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[dates[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,[\"A\",\"B\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"20130102\":\"20130104\",[\"A\",\"B\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"20130102\":\"20130104\",[\"B\",\"A\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[dates[0],\"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[dates[0],\"A\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3:5, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#비교 loc는 슬라이싱 할때 끝부분까지로 인식(끝부분 포함됨) iloc는 끝부분제외\n",
    "#df.loc[3:5, 0:2] 아 맞다 이런 식으로 숫자 인덱스로 안됬다\n",
    "df.loc[\"20130104\":\"20130105\", \"A\":\"B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[1,2,4],[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iat[1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean indexing (조건에 따른 컬럼 선택)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"A\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.copy()\n",
    "df2[\"E\"]=[\"one\", \"one\", \"two\", \"three\", \"four\", \"three\"]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2[\"E\"].isin([\"two\", \"four\"])]\n",
    "#isin()안에 []로 넣어야하는 듯 (한 개의 경우에도)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([1,2,3,4,5,6], index=pd.date_range(\"20130102\", periods=6))\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"F\"]=s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[dates[0],\"A\"] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iat[0, 1] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"D\"] = np.array([5]*len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2[df2 > 0] = -df2\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing data (2024-01-29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.reindex(index=dates[0:4], columns=list(df.columns)+[\"E\"])\n",
    "df.loc[dates[0]:dates[1], \"E\"] = 1\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(how=\"any\") #결측치 있으면 다 제거하는 옵션인듯?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.fillna(value=5) #결측치를 특정 값으로 다 바꿔서 채우는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(df1) #결측치가 있는가에 대한 T/F판단 있으면 T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations (2024-01-30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean() #NaN값있으면 합산, 갯수에서 제외하고 평균 내는 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.mean(axis=1)) \n",
    "# 마찬가지로 NaN값있으면 합산, 갯수에서 제외하고 평균 내는 듯, 단 axis=1이면 행 별로 모든 컬럼의 값의 평균 내줌\n",
    "# axis = 1말고 그냥 인자로 1만 줘도 동일한 결과가 나오는 듯 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 3, 5, np.nan, 6, 8], index=dates)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 3, 5, np.nan, 6, 8], index=dates).shift(2)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series     \n",
    "Series의 메소드인 shift가 뭐하는 녀석인지 몰라서 문서에 들어가보니 아래와 같이 서술되어있었다   \n",
    "shift([periods, freq, axis, fill_value, suffix])    \n",
    "Shift index by desired number of periods with an optional time freq.    \n",
    "자세한 내용은 모르겠지만 대강 값들을 index를 기준으로 준 값만큼 이동시키는 듯하다   \n",
    "1일과 2일의 경우 이전 인덱스에 해당하는 데이터가 없으니 NaN로 결측치가 된 것이고    \n",
    "3,4,5일의 경우 인덱스상으로 2이전의 값들이 존재했으니 해당값들로 바뀌었고   \n",
    "6일의 경우 인덱스상으로 2이전의 값이 NaN로 결측치 였기에 결측치로 되었는 듯하다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sub(s, axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame\n",
    "이번엔 df의 메소드인 sub에 대하여 설명이 없어서 찾아보니 아래와 같이 메소드로 설명되어있었고 잘 이해가 되지 않아 좀더 자세한 독스에 들어갔다    \n",
    "sub(other[, axis, level, fill_value])       \n",
    "Get Subtraction of dataframe and other, element-wise (binary operator sub).     \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sub.html#pandas.DataFrame.sub   \n",
    "DataFrame.sub(other, axis='columns', level=None, fill_value=None)   \n",
    "대강 구조를 보니 df에 대하여 빼기를 해주는데 sub()안에 들어있는 값으로 빼주는 것으로 들어올 수 있는 other로는 scalar, sequence, Series, dict or DataFrame이 가능하다고 한다 이중 sequence는 정확히 뭔지 모르겠어서 찾아보니     \n",
    "https://wikidocs.net/84391      \n",
    "내용을 참고하였다 대강 리스트, 문자열, 튜플 이 세가지 자료형이라고 생각하면 될듯하다    \n",
    "그리고 axis에 대하여 0 or index , 1 or columns의 옵션이 있는데 기본값은 colunms로 되어있다  \n",
    "fill_value는 결측치를 만났을 때 특정값으로 바꿔넣어줄 것인지 선택하는 옵션으로 기본값은 none로 되어있다     \n",
    "level 옵션에 대해서는 잘모르겠다 예제도 한문제 뿐인데 잘 이해가 되지 않는다 대강 멀티인덱스를 사용할 경우에 사용하는 느낌인데 예제를 아래 그대로 가져와서 해보고 이해해보도록 하겠다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### level 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_example_df = pd.DataFrame({'angles': [0, 3, 4],\n",
    "                   'degrees': [360, 180, 360]},\n",
    "                  index=['circle', 'triangle', 'rectangle'])\n",
    "level_example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_example_df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
    "                             'degrees': [360, 180, 360, 360, 540, 720]},\n",
    "                            index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
    "                                   ['circle', 'triangle', 'rectangle',\n",
    "                                    'square', 'pentagon', 'hexagon']])\n",
    "level_example_df_multindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(level_example_df.div(level_example_df_multindex, level=1))\n",
    "#원래 예제에는 ,fill_value=0으로 결측치 0으로 바꿔주는 옵션이 추가되어있었다\n",
    "#뭔가 알듯말듯한데 chatGPT를 통해 설명을 들으니 알 것 같았다\n",
    "#https://chat.openai.com/share/73654015-96b4-4fb3-b6e3-243526afb670"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "print(df.mean(),'\\n')\n",
    "print(df.mean()*5.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.agg(lambda x: np.mean(x)*5.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df*101.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.transform(lambda x: x*101.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agg는 대강은 알듯한데 transform은 agg와 뭐가 다른지 모르겠다    \n",
    "추가로 유사한 것에 apply도 있던 것으로 기억하는데 여기는 왜 빠져있고 차이가 뭔지도 궁금하다     \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html#pandas.DataFrame.agg   \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.transform.html#pandas.DataFrame.transform   \n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/gotchas.html#gotchas-udf-mutation   \n",
    "chatGPT에게 차이를 물어본 내용:\n",
    "https://chat.openai.com/share/654feb01-8d50-481e-8c7a-ca160e1e74a4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.random.randint(0,7,size=10))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([\"A\", \"B\", \"C\", \"Aaba\", \"Baca\", np.nan, \"CABA\", \"dog\", \"cat\"])\n",
    "print(s)\n",
    "s.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.Series:\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series     \n",
    "Vectorized String Methods:\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html#text-string-methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge (2024-01-31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(10,4)) \n",
    "#np.random.randn(m,n) : 평균0, 표준편차1의 가우시안 표준정규분포 난수를 matrix array(m,n) 생성\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.random.randn(m,n) https://nittaku.tistory.com/443    \n",
    "docs : https://numpy.org/doc/stable/reference/random/generated/numpy.random.randn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces = [df[:3], df[3:7], df[7:]]\n",
    "pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(pieces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({\"key\": [\"foo\", \"foo\"], \"lval\": [1, 2]})\n",
    "right = pd.DataFrame({\"key\": [\"foo\", \"foo\"], \"rval\": [4, 5]})\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left, right, on=\"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({\"key\": [\"foo\", \"bar\"], \"lval\": [1, 2]})\n",
    "right = pd.DataFrame({\"key\": [\"foo\", \"bar\"], \"rval\": [4, 5]})\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left, right, on=\"key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping (2024-02-01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into groups based on some criteria\n",
    "\n",
    "Applying a function to each group independently\n",
    "\n",
    "Combining the results into a data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\"A\": [\"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"foo\"], \n",
    "     \"B\": [\"one\", \"one\", \"two\", \"three\", \"two\", \"two\", \"one\", \"three\"], \n",
    "     \"C\": np.random.randn(8),\n",
    "     \"D\": np.random.randn(8),}\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"A\")[[\"C\", \"D\"]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"A\", \"B\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping (2024-02-02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = [\n",
    "    [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"], \n",
    "    [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n",
    "]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names = [\"first\", \"second\"])\n",
    "df = pd.DataFrame(np.random.randn(8,2), index=index, columns=[\"A\", \"B\"])\n",
    "df2 = df[:4]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = df2.stack() #future_stack=True\n",
    "stacked #왜인지는 모르겠지만 저 옵션 빼줘야 제대로 실행됨 결과는 그리 다르지 않은 것으로 보임 나중에 질문해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.stack.html#pandas.DataFrame.stack   \n",
    "부분을 보니 pandas2.0에서 pandas 3.0의 방식을 사용할 때 해주던 방식으로 유추되는데"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.0버전 쓰고 있는 것이 맞는데 왜 안되는 거지..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.unstack(1) # 행열 바꿔서 해제하는듯?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.unstack(0) # 무슨 방식으로 바꾸는지는 모르겠지만 째든 바꿔서 해제하는듯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"one\", \"one\", \"two\", \"three\"] * 3,\n",
    "        \"B\": [\"A\", \"B\", \"C\"] * 4,\n",
    "        \"C\": [\"foo\", \"foo\", \"foo\", \"bar\", \"bar\", \"bar\"] * 2,\n",
    "        \"D\": np.random.randn(12),\n",
    "        \"E\": np.random.randn(12),\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df, values=\"D\", index=[\"A\", \"B\"], columns=[\"C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series (2024-02-03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시계열 데이터에서 1초 마다 측정된 데이터를 5분 마다 측정된 데이터의 형태로 바꾸고 싶을 때 어떻게 해야하는지     \n",
    "그리고 그 시계열 단위인 주기(frequency)를 다시 샘플링 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range(\"1/1/2012\", periods=100, freq =\"s\") #대강 시작기준날짜, 몇개, (데이터간 차이나는)단위 느낌인듯하다\n",
    "ts = pd.Series(np.random.randint(0,500,len(rng)), index=rng)\n",
    "ts.resample(\"5Min\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### resample에 대하여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.date_range(\"2018-01-01\", periods=5, freq=\"h\")\n",
    "ts2 = pd.Series(range(len(idx)), index=idx)\n",
    "ts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts2.resample(\"2h\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(ts2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.resample.html#pandas.Series.resample   \n",
    "우선 2.0.0버전 이후로는 사라지게 될 듯한 기능이며 후에는 frame.T.resample을 대신 사용하라고 한다    \n",
    "(지금 내가 사용하는 pandas 버전이 2.0.3인데 아직 존재는 하는듯하다?)    \n",
    "resample: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-resampling     \n",
    "흠 frame.T.resample이 뭔지 궁금해서 검색했는데 따로 나오지는 않은 것같다    \n",
    "(Dataframe.T정도는 있긴한데 다른내용으로 행과 열을 바꿔주는 transpose를 의미하는 듯하다)   \n",
    "그리고 그냥 series, df, df의 groupby했을때 series와 df 모두에 사용가능한 듯하다     \n",
    "그런데 쓰이는 파라미터의 rule에 대해서 어떤 것을 쓸 수 있는 지 궁금해서 알고 싶은데 그냥 DataOffset, Timedelta or str로 적혀있다    \n",
    "현재 예제들로 확인 된 것은 str으로 적을 때 숫자+ 시간은 'h', 초는 's', 분은 month의 m과 중복되서 그런지 'min'로 쓰이는 것을 확인하였다      \n",
    "관련한 듯한 내용: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects   \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.tseries.offsets.DateOffset.html#pandas.tseries.offsets.DateOffset      \n",
    "timedelta: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timedelta.html#pandas.Timedelta   \n",
    "GPT한테 물어봐도 https://chat.openai.com/share/4e050491-79e0-44a5-bd1d-38a4f2d1e92f     \n",
    "크게 다르진 않는 듯하다     \n",
    "그냥 관련한 듯한 내용에 적힌 string부분을 참고하는 것만으로도 충분한듯 하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range(\"3/6/2012 00:00\", periods=5, freq=\"D\")\n",
    "ts = pd.Series(np.random.random(len(rng)),rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_utc = ts.tz_localize(\"UTC\")\n",
    "ts_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_utc.tz_convert(\"US/Eastern\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng + pd.offsets.BusinessDay(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categoricals (2024-02-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\"id\": [1,2,3,4,5,6], \"raw_grade\": [\"a\", \"b\", \"b\", \"a\", \"a\", \"e\"]}\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"grade\"] = df[\"raw_grade\"].astype(\"category\") # 타입을 category로 변경하여 새로운 컬럼으로써 추가\n",
    "df[\"grade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_categorics = [\"very good\", \"good\", \"very bad\"] # 변경해줄 새로운 카테고리들\n",
    "df[\"grade\"] = df[\"grade\"].cat.rename_categories(new_categorics) # 기존 카테고리를 새로운 카테고리로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"grade\"] = df[\"grade\"].cat.set_categories(\n",
    "    [\"very bad\", \"bad\", \"medium\", \"good\", \"very good\"]\n",
    ")\n",
    "df[\"grade\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.cat.html#pandas.Series.cat \n",
    ".cat.rename_categories(new_categorics)는 기존 카테고리를 새로운 카테고리로 변경하는 것이고  \n",
    ".cat.set_categories(new_categorics)는 기존 카테고리를 새로운 카테고리로 변경하면서 추가로 없던 카테고리도 추가해줄 수 있다(카테고리 갯수를 늘릴 수 있다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"grade\") # 대신 정렬의 기준은 어휘적 순서가 아닌 범주에서 매겨진 값의 순서대로 순서가 매겨짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.groupby(\"grade\", observed=False).size()) \n",
    "# size로 크기를 구할 수 있기 때문에 이 방식을 통해 각 범주에 해당되는 값의 빈도수도 확인할 수 있다\n",
    "# observed=False하면 카테고리에 대해 0인 것도 표시가 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting (2024-02-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.close(\"all\") # 왜 이것부터 시작한지는 모르겠지만 열려있는 모든 figure창을 닫아주는 메소드인듯하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(np.random.randn(1000), index=pd.date_range(\"1/1/2000\", periods=1000))\n",
    "ts = ts.cumsum()\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cumsum은 누적합계를 해주는 메소드인듯하다   \n",
    "https://pandas.pydata.org/docs/reference/api/pandas.Series.cumsum.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    np.random.randn(1000,4), index=ts.index, columns=[\"A\", \"B\", \"C\", \"D\" ]\n",
    ")\n",
    "df = df.cumsum()\n",
    "plt.figure();\n",
    "df.plot();\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬에서느 일반적으로 세미콜론 안 적는 듯한데 왜 적어준지 모르겠음    \n",
    "https://chat.openai.com/share/4ae0e28e-30a6-4f04-bf75-6eb8dfc91ec1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and exporting data (2024-02-06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(0,5,(10,5)))\n",
    "df.to_csv(\"foo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"foo.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주의 할점:  \n",
    "CSV 형식으로 부터 읽어올 때 주의할 점은 기존 행 인덱스를 인식하지 못하고 행 인덱스를 가지는 새로운 열이 추가로 잡힌다는 것입니다.   \n",
    "따라서 저장할 당시에는 4개였던 열의 개수가 5개가 되어있는 것을 확인할 수 있습니다.      \n",
    "이를 해결하기 위해서 저장할 떄 index_rabel=False를 해주면 제외하고 저장할 수 있다\n",
    "아니면 불러올 때 index_col=0를 통해 첫번째 열을 인덱스로 사용하여 저장된 인덱스를 그냥 바로 사용하도록 설정해줄 수도 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"foo.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(\"foo.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_hdf('foo.h5', 'df') #모듈 추가 설치해야하는듯한데 쓸일없을듯하여 패스하였다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그냥 실행시 실패 추가로 모듈 설치해줘야하는 듯 \n",
    "(그래서 pytalbes라는 것을 설치해야 쓸 수 있을 듯한데 당장 쓸일없을듯하여 패스하였다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\n",
    "\t\"name\": \"ImportError\",\n",
    "\t\"message\": \"Missing optional dependency 'pytables'.  Use pip or conda to install pytables.\",\n",
    "\t\"stack\": \"---------------------------------------------------------------------------\n",
    "ModuleNotFoundError                       Traceback (most recent call last)\n",
    "File c:\\\\Users\\\\kssg1\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\lib\\\\site-packages\\\\pandas\\\\compat\\\\_optional.py:142, in import_optional_dependency(name, extra, errors, min_version)\n",
    "    141 try:\n",
    "--> 142     module = importlib.import_module(name)\n",
    "    143 except ImportError:\n",
    "\n",
    "File c:\\\\Users\\\\kssg1\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\lib\\\\importlib\\\\__init__.py:127, in import_module(name, package)\n",
    "    126         level += 1\n",
    "--> 127 return _bootstrap._gcd_import(name[level:], package, level)\n",
    "\n",
    "File <frozen importlib._bootstrap>:1014, in _gcd_import(name, package, level)\n",
    "\n",
    "File <frozen importlib._bootstrap>:991, in _find_and_load(name, import_)\n",
    "\n",
    "File <frozen importlib._bootstrap>:973, in _find_and_load_unlocked(name, import_)\n",
    "\n",
    "ModuleNotFoundError: No module named 'tables'\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "ImportError                               Traceback (most recent call last)\n",
    "Cell In[115], line 1\n",
    "----> 1 df.to_hdf('foo.h5', 'df')\n",
    "\n",
    "File c:\\\\Users\\\\kssg1\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py:2682, in NDFrame.to_hdf(self, path_or_buf, key, mode, complevel, complib, append, format, index, min_itemsize, nan_rep, dropna, data_columns, errors, encoding)\n",
    "   2678 from pandas.io import pytables\n",
    "   2680 # Argument 3 to \\\"to_hdf\\\" has incompatible type \\\"NDFrame\\\"; expected\n",
    "   2681 # \\\"Union[DataFrame, Series]\\\" [arg-type]\n",
    "-> 2682 pytables.to_hdf(\n",
    "   2683     path_or_buf,\n",
    "   2684     key,\n",
    "   2685     self,  # type: ignore[arg-type]\n",
    "   2686     mode=mode,\n",
    "   2687     complevel=complevel,\n",
    "   2688     complib=complib,\n",
    "   2689     append=append,\n",
    "   2690     format=format,\n",
    "   2691     index=index,\n",
    "   2692     min_itemsize=min_itemsize,\n",
    "   2693     nan_rep=nan_rep,\n",
    "   2694     dropna=dropna,\n",
    "   2695     data_columns=data_columns,\n",
    "   2696     errors=errors,\n",
    "   2697     encoding=encoding,\n",
    "   2698 )\n",
    "\n",
    "File c:\\\\Users\\\\kssg1\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\lib\\\\site-packages\\\\pandas\\\\io\\\\pytables.py:302, in to_hdf(path_or_buf, key, value, mode, complevel, complib, append, format, index, min_itemsize, nan_rep, dropna, data_columns, errors, encoding)\n",
    "    300 path_or_buf = stringify_path(path_or_buf)\n",
    "    301 if isinstance(path_or_buf, str):\n",
    "--> 302     with HDFStore(\n",
    "    303         path_or_buf, mode=mode, complevel=complevel, complib=complib\n",
    "    304     ) as store:\n",
    "    305         f(store)\n",
    "    306 else:\n",
    "\n",
    "File c:\\\\Users\\\\kssg1\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\lib\\\\site-packages\\\\pandas\\\\io\\\\pytables.py:560, in HDFStore.__init__(self, path, mode, complevel, complib, fletcher32, **kwargs)\n",
    "    557 if \\\"format\\\" in kwargs:\n",
    "    558     raise ValueError(\\\"format is not a defined argument for HDFStore\\\")\n",
    "--> 560 tables = import_optional_dependency(\\\"tables\\\")\n",
    "    562 if complib is not None and complib not in tables.filters.all_complibs:\n",
    "    563     raise ValueError(\n",
    "    564         f\\\"complib only supports {tables.filters.all_complibs} compression.\\\"\n",
    "    565     )\n",
    "\n",
    "File c:\\\\Users\\\\kssg1\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\lib\\\\site-packages\\\\pandas\\\\compat\\\\_optional.py:145, in import_optional_dependency(name, extra, errors, min_version)\n",
    "    143 except ImportError:\n",
    "    144     if errors == \\\"raise\\\":\n",
    "--> 145         raise ImportError(msg)\n",
    "    146     return None\n",
    "    148 # Handle submodules: if we have submodule, grab parent module from sys.modules\n",
    "\n",
    "ImportError: Missing optional dependency 'pytables'.  Use pip or conda to install pytables.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 생소한 파일 형식자들에 대한 gpt 답변 (+pickle)\n",
    "https://chat.openai.com/share/ee9a3e69-bbd0-44c0-8e95-bf87a586f75c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"foo.xlsx\", sheet_name=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel(\"foo.xlsx\", \"Sheet1\", index_col=None, na_values=[\"NA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gotchas (2024-02-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if pd.Series([False, True, False]):\n",
    "#      print(\"I was true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\n",
    "\t\"name\": \"ValueError\",\n",
    "\t\"message\": \"The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\",\n",
    "\t\"stack\": \"---------------------------------------------------------------------------\n",
    "ValueError                                Traceback (most recent call last)\n",
    "Cell In[117], line 1\n",
    "----> 1 if pd.Series([False, True, False]):\n",
    "      2      print(\\\"I was true\\\")\n",
    "\n",
    "File c:\\\\Users\\\\kssg1\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py:1466, in NDFrame.__nonzero__(self)\n",
    "   1464 @final\n",
    "   1465 def __nonzero__(self) -> NoReturn:\n",
    "-> 1466     raise ValueError(\n",
    "   1467         f\\\"The truth value of a {type(self).__name__} is ambiguous. \\\"\n",
    "   1468         \\\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\\\"\n",
    "   1469     )\n",
    "\n",
    "ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이로써 한번 완독?완타가 끝났다\n",
    "    중간 import 다시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View부분 (2024-02-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n",
       "               '2013-01-05', '2013-01-06'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dates = pd.date_range(\"20130101\", periods=6)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.084276</td>\n",
       "      <td>-0.990418</td>\n",
       "      <td>0.766975</td>\n",
       "      <td>-0.105054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.060532</td>\n",
       "      <td>-1.116166</td>\n",
       "      <td>-0.190412</td>\n",
       "      <td>1.033047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>-2.707503</td>\n",
       "      <td>0.436719</td>\n",
       "      <td>0.545674</td>\n",
       "      <td>-0.766680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>0.006458</td>\n",
       "      <td>1.400895</td>\n",
       "      <td>-2.140044</td>\n",
       "      <td>-1.204554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.271720</td>\n",
       "      <td>-0.563553</td>\n",
       "      <td>-0.286793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>-0.173206</td>\n",
       "      <td>-1.739706</td>\n",
       "      <td>1.409944</td>\n",
       "      <td>0.249190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-01  0.084276 -0.990418  0.766975 -0.105054\n",
       "2013-01-02 -0.060532 -1.116166 -0.190412  1.033047\n",
       "2013-01-03 -2.707503  0.436719  0.545674 -0.766680\n",
       "2013-01-04  0.006458  1.400895 -2.140044 -1.204554\n",
       "2013-01-05  0.015899  0.271720 -0.563553 -0.286793\n",
       "2013-01-06 -0.173206 -1.739706  1.409944  0.249190"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list(\"ABCD\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0842757 , -0.99041755,  0.7669749 , -0.10505376],\n",
       "       [-0.06053217, -1.1161663 , -0.19041221,  1.03304714],\n",
       "       [-2.70750326,  0.43671926,  0.5456739 , -0.76667979],\n",
       "       [ 0.0064583 ,  1.40089451, -2.14004445, -1.20455429],\n",
       "       [ 0.0158991 ,  0.27171997, -0.56355304, -0.2867926 ],\n",
       "       [-0.17320589, -1.73970626,  1.40994425,  0.24918956]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_numpy() #df풀고 어레이로 바꾸는 방식인듯했다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 6 entries, 2013-01-01 to 2013-01-06\n",
      "Freq: D\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A       6 non-null      float64\n",
      " 1   B       6 non-null      float64\n",
      " 2   C       6 non-null      float64\n",
      " 3   D       6 non-null      float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 240.0 bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.472435</td>\n",
       "      <td>-0.289493</td>\n",
       "      <td>-0.028569</td>\n",
       "      <td>-0.180141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.098405</td>\n",
       "      <td>1.181318</td>\n",
       "      <td>1.249215</td>\n",
       "      <td>0.783149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.707503</td>\n",
       "      <td>-1.739706</td>\n",
       "      <td>-2.140044</td>\n",
       "      <td>-1.204554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.145037</td>\n",
       "      <td>-1.084729</td>\n",
       "      <td>-0.470268</td>\n",
       "      <td>-0.646708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.027037</td>\n",
       "      <td>-0.359349</td>\n",
       "      <td>0.177631</td>\n",
       "      <td>-0.195923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.013539</td>\n",
       "      <td>0.395469</td>\n",
       "      <td>0.711650</td>\n",
       "      <td>0.160629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.084276</td>\n",
       "      <td>1.400895</td>\n",
       "      <td>1.409944</td>\n",
       "      <td>1.033047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         B         C         D\n",
       "count  6.000000  6.000000  6.000000  6.000000\n",
       "mean  -0.472435 -0.289493 -0.028569 -0.180141\n",
       "std    1.098405  1.181318  1.249215  0.783149\n",
       "min   -2.707503 -1.739706 -2.140044 -1.204554\n",
       "25%   -0.145037 -1.084729 -0.470268 -0.646708\n",
       "50%   -0.027037 -0.359349  0.177631 -0.195923\n",
       "75%    0.013539  0.395469  0.711650  0.160629\n",
       "max    0.084276  1.400895  1.409944  1.033047"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.472435</td>\n",
       "      <td>-0.289493</td>\n",
       "      <td>-0.028569</td>\n",
       "      <td>-0.180141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.098405</td>\n",
       "      <td>1.181318</td>\n",
       "      <td>1.249215</td>\n",
       "      <td>0.783149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.707503</td>\n",
       "      <td>-1.739706</td>\n",
       "      <td>-2.140044</td>\n",
       "      <td>-1.204554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.145037</td>\n",
       "      <td>-1.084729</td>\n",
       "      <td>-0.470268</td>\n",
       "      <td>-0.646708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.027037</td>\n",
       "      <td>-0.359349</td>\n",
       "      <td>0.177631</td>\n",
       "      <td>-0.195923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.013539</td>\n",
       "      <td>0.395469</td>\n",
       "      <td>0.711650</td>\n",
       "      <td>0.160629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.084276</td>\n",
       "      <td>1.400895</td>\n",
       "      <td>1.409944</td>\n",
       "      <td>1.033047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         B         C         D\n",
       "count  6.000000  6.000000  6.000000  6.000000\n",
       "mean  -0.472435 -0.289493 -0.028569 -0.180141\n",
       "std    1.098405  1.181318  1.249215  0.783149\n",
       "min   -2.707503 -1.739706 -2.140044 -1.204554\n",
       "25%   -0.145037 -1.084729 -0.470268 -0.646708\n",
       "50%   -0.027037 -0.359349  0.177631 -0.195923\n",
       "75%    0.013539  0.395469  0.711650  0.160629\n",
       "max    0.084276  1.400895  1.409944  1.033047"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.472435</td>\n",
       "      <td>-0.289493</td>\n",
       "      <td>-0.028569</td>\n",
       "      <td>-0.180141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.098405</td>\n",
       "      <td>1.181318</td>\n",
       "      <td>1.249215</td>\n",
       "      <td>0.783149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.707503</td>\n",
       "      <td>-1.739706</td>\n",
       "      <td>-2.140044</td>\n",
       "      <td>-1.204554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.145037</td>\n",
       "      <td>-1.084729</td>\n",
       "      <td>-0.470268</td>\n",
       "      <td>-0.646708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.027037</td>\n",
       "      <td>-0.359349</td>\n",
       "      <td>0.177631</td>\n",
       "      <td>-0.195923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.013539</td>\n",
       "      <td>0.395469</td>\n",
       "      <td>0.711650</td>\n",
       "      <td>0.160629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.084276</td>\n",
       "      <td>1.400895</td>\n",
       "      <td>1.409944</td>\n",
       "      <td>1.033047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         B         C         D\n",
       "count  6.000000  6.000000  6.000000  6.000000\n",
       "mean  -0.472435 -0.289493 -0.028569 -0.180141\n",
       "std    1.098405  1.181318  1.249215  0.783149\n",
       "min   -2.707503 -1.739706 -2.140044 -1.204554\n",
       "25%   -0.145037 -1.084729 -0.470268 -0.646708\n",
       "50%   -0.027037 -0.359349  0.177631 -0.195923\n",
       "75%    0.013539  0.395469  0.711650  0.160629\n",
       "max    0.084276  1.400895  1.409944  1.033047"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.info() #info는 자체에 print가 포함 된듯하다 항상 자동으로 출력이 되었다\n",
    "display(df.describe())\n",
    "display(df.describe(include='all'))\n",
    "display(df.describe(include=['int','float64'])) \n",
    "# 'float64 자리에 'object' or 'O' , category 등 나오는 것을 바라는 형식을 입력하면 된다 \n",
    "# 여러개 하고싶다면 ['',''] 이런 식으로 리스트 안에 문자열로 형식을 여러개 넣어주면 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원래 조금 더 할려했는데 피곤하고 시간이 늦은 관계로 이정도에서 마무리 짓도록 하겠다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
